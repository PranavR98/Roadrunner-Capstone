{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e34b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.metrics import TruePositives, FalsePositives, TrueNegatives, FalseNegatives, BinaryAccuracy, Precision, Recall, Accuracy, AUC\n",
    "from keras.optimizers import SGD,RMSprop,adam\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "072274fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(history):\n",
    "    mets = history.history\n",
    "    \n",
    "    for metric_name, metric_values in mets.items():\n",
    "        print(f\"{metric_name}: {metric_values[-1]}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29ebadf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>manifestid</th>\n",
       "      <th>documentid</th>\n",
       "      <th>Full</th>\n",
       "      <th>uploaddatetimejsonmetadata</th>\n",
       "      <th>Folder</th>\n",
       "      <th>File</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>SIGN OUT</th>\n",
       "      <th>ALLIGATOR</th>\n",
       "      <th>CATEGORY 1</th>\n",
       "      <th>CATEGORY 2</th>\n",
       "      <th>CATEGORY 3</th>\n",
       "      <th>POOR QUALITY</th>\n",
       "      <th>NOTES</th>\n",
       "      <th>onpremfilepathjsonmetadata</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXAMPLE</td>\n",
       "      <td>EXAMPLE</td>\n",
       "      <td>EXAMPLE</td>\n",
       "      <td>EXAMPLE</td>\n",
       "      <td>EXAMPLE</td>\n",
       "      <td>EXAMPLE</td>\n",
       "      <td>EXAMPLE</td>\n",
       "      <td>Vogt</td>\n",
       "      <td>27-Apr</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>dunnage</td>\n",
       "      <td>strap</td>\n",
       "      <td>airbag</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>EXAMPLE</td>\n",
       "      <td>PROGRESS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXAMPLE</td>\n",
       "      <td>EXAMPLE</td>\n",
       "      <td>EXAMPLE</td>\n",
       "      <td>EXAMPLE</td>\n",
       "      <td>EXAMPLE</td>\n",
       "      <td>EXAMPLE</td>\n",
       "      <td>EXAMPLE</td>\n",
       "      <td>Vogt</td>\n",
       "      <td>27-Apr</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>restack</td>\n",
       "      <td>return to level</td>\n",
       "      <td>pass</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>EXAMPLE</td>\n",
       "      <td>5000</td>\n",
       "      <td>&lt;-- Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180426</td>\n",
       "      <td>43417541</td>\n",
       "      <td>83328644</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>4/7/2023 7:25</td>\n",
       "      <td>328</td>\n",
       "      <td>644-0.jpg</td>\n",
       "      <td>Vogt</td>\n",
       "      <td>29-Apr</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>pass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\\\\\\\offtffs01\\\\Transflo\\\\Storage\\\\LHTRAILER\\\\C...</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>&lt;-- % Complete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>180429</td>\n",
       "      <td>43418071</td>\n",
       "      <td>83328656</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>4/7/2023 7:26</td>\n",
       "      <td>328</td>\n",
       "      <td>656-0.jpg</td>\n",
       "      <td>Vogt</td>\n",
       "      <td>29-Apr</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>dunnage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\\\\\\\offtffs01\\\\Transflo\\\\Storage\\\\LHTRAILER\\\\C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180421</td>\n",
       "      <td>43416911</td>\n",
       "      <td>83328720</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>4/7/2023 7:24</td>\n",
       "      <td>328</td>\n",
       "      <td>720-0.jpg</td>\n",
       "      <td>Vogt</td>\n",
       "      <td>29-Apr</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>pass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\\\\\\\offtffs01\\\\Transflo\\\\Storage\\\\LHTRAILER\\\\C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id manifestid documentid     Full uploaddatetimejsonmetadata   Folder  \\\n",
       "0  EXAMPLE    EXAMPLE    EXAMPLE  EXAMPLE                    EXAMPLE  EXAMPLE   \n",
       "1  EXAMPLE    EXAMPLE    EXAMPLE  EXAMPLE                    EXAMPLE  EXAMPLE   \n",
       "2   180426   43417541   83328644     TRUE              4/7/2023 7:25      328   \n",
       "3   180429   43418071   83328656    FALSE              4/7/2023 7:26      328   \n",
       "4   180421   43416911   83328720    FALSE              4/7/2023 7:24      328   \n",
       "\n",
       "        File LABEL SIGN OUT ALLIGATOR CATEGORY 1       CATEGORY 2 CATEGORY 3  \\\n",
       "0    EXAMPLE  Vogt   27-Apr      TRUE    dunnage            strap     airbag   \n",
       "1    EXAMPLE  Vogt   27-Apr     FALSE    restack  return to level       pass   \n",
       "2  644-0.jpg  Vogt   29-Apr     FALSE       pass              NaN        NaN   \n",
       "3  656-0.jpg  Vogt   29-Apr     FALSE    dunnage              NaN        NaN   \n",
       "4  720-0.jpg  Vogt   29-Apr     FALSE       pass              NaN        NaN   \n",
       "\n",
       "  POOR QUALITY NOTES                         onpremfilepathjsonmetadata  \\\n",
       "0         True   ...                                            EXAMPLE   \n",
       "1        False   ...                                            EXAMPLE   \n",
       "2        False   NaN  \\\\\\\\offtffs01\\\\Transflo\\\\Storage\\\\LHTRAILER\\\\C...   \n",
       "3        False   NaN  \\\\\\\\offtffs01\\\\Transflo\\\\Storage\\\\LHTRAILER\\\\C...   \n",
       "4        False   NaN  \\\\\\\\offtffs01\\\\Transflo\\\\Storage\\\\LHTRAILER\\\\C...   \n",
       "\n",
       "  Unnamed: 16     Unnamed: 17  \n",
       "0    PROGRESS             NaN  \n",
       "1        5000       <-- Count  \n",
       "2     100.00%  <-- % Complete  \n",
       "3         NaN             NaN  \n",
       "4         NaN             NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\tfurr\\\\Downloads\\\\Working Labeling Checklist - Sheet1.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0f9f8e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>manifestid</th>\n",
       "      <th>documentid</th>\n",
       "      <th>Full</th>\n",
       "      <th>uploaddatetimejsonmetadata</th>\n",
       "      <th>Folder</th>\n",
       "      <th>File</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>SIGN OUT</th>\n",
       "      <th>ALLIGATOR</th>\n",
       "      <th>CATEGORY 1</th>\n",
       "      <th>CATEGORY 2</th>\n",
       "      <th>CATEGORY 3</th>\n",
       "      <th>POOR QUALITY</th>\n",
       "      <th>NOTES</th>\n",
       "      <th>onpremfilepathjsonmetadata</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>ext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180426</td>\n",
       "      <td>43417541</td>\n",
       "      <td>83328644</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>4/7/2023 7:25</td>\n",
       "      <td>328</td>\n",
       "      <td>644-0.jpg</td>\n",
       "      <td>Vogt</td>\n",
       "      <td>29-Apr</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>pass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\\\\\\\offtffs01\\\\Transflo\\\\Storage\\\\LHTRAILER\\\\C...</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>&lt;-- % Complete</td>\n",
       "      <td>328\\644-0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>180429</td>\n",
       "      <td>43418071</td>\n",
       "      <td>83328656</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>4/7/2023 7:26</td>\n",
       "      <td>328</td>\n",
       "      <td>656-0.jpg</td>\n",
       "      <td>Vogt</td>\n",
       "      <td>29-Apr</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>dunnage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\\\\\\\offtffs01\\\\Transflo\\\\Storage\\\\LHTRAILER\\\\C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>328\\656-0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180421</td>\n",
       "      <td>43416911</td>\n",
       "      <td>83328720</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>4/7/2023 7:24</td>\n",
       "      <td>328</td>\n",
       "      <td>720-0.jpg</td>\n",
       "      <td>Vogt</td>\n",
       "      <td>29-Apr</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>pass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\\\\\\\offtffs01\\\\Transflo\\\\Storage\\\\LHTRAILER\\\\C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>328\\720-0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180420</td>\n",
       "      <td>43416841</td>\n",
       "      <td>83328779</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>4/7/2023 7:24</td>\n",
       "      <td>328</td>\n",
       "      <td>779-0.jpg</td>\n",
       "      <td>Vogt</td>\n",
       "      <td>29-Apr</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>airbag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\\\\\\\offtffs01\\\\Transflo\\\\Storage\\\\LHTRAILER\\\\C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>328\\779-0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>180422</td>\n",
       "      <td>43416961</td>\n",
       "      <td>83328780</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>4/7/2023 7:24</td>\n",
       "      <td>328</td>\n",
       "      <td>780-0.jpg</td>\n",
       "      <td>Vogt</td>\n",
       "      <td>29-Apr</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>pass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\\\\\\\offtffs01\\\\Transflo\\\\Storage\\\\LHTRAILER\\\\C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>328\\780-0.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id manifestid documentid   Full uploaddatetimejsonmetadata Folder  \\\n",
       "2  180426   43417541   83328644   TRUE              4/7/2023 7:25    328   \n",
       "3  180429   43418071   83328656  FALSE              4/7/2023 7:26    328   \n",
       "4  180421   43416911   83328720  FALSE              4/7/2023 7:24    328   \n",
       "5  180420   43416841   83328779   TRUE              4/7/2023 7:24    328   \n",
       "6  180422   43416961   83328780   TRUE              4/7/2023 7:24    328   \n",
       "\n",
       "        File LABEL SIGN OUT ALLIGATOR CATEGORY 1 CATEGORY 2 CATEGORY 3  \\\n",
       "2  644-0.jpg  Vogt   29-Apr     FALSE       pass        NaN        NaN   \n",
       "3  656-0.jpg  Vogt   29-Apr     FALSE    dunnage        NaN        NaN   \n",
       "4  720-0.jpg  Vogt   29-Apr     FALSE       pass        NaN        NaN   \n",
       "5  779-0.jpg  Vogt   29-Apr      TRUE     airbag        NaN        NaN   \n",
       "6  780-0.jpg  Vogt   29-Apr     FALSE       pass        NaN        NaN   \n",
       "\n",
       "  POOR QUALITY NOTES                         onpremfilepathjsonmetadata  \\\n",
       "2        False   NaN  \\\\\\\\offtffs01\\\\Transflo\\\\Storage\\\\LHTRAILER\\\\C...   \n",
       "3        False   NaN  \\\\\\\\offtffs01\\\\Transflo\\\\Storage\\\\LHTRAILER\\\\C...   \n",
       "4        False   NaN  \\\\\\\\offtffs01\\\\Transflo\\\\Storage\\\\LHTRAILER\\\\C...   \n",
       "5        False   NaN  \\\\\\\\offtffs01\\\\Transflo\\\\Storage\\\\LHTRAILER\\\\C...   \n",
       "6        False   NaN  \\\\\\\\offtffs01\\\\Transflo\\\\Storage\\\\LHTRAILER\\\\C...   \n",
       "\n",
       "  Unnamed: 16     Unnamed: 17            ext  \n",
       "2     100.00%  <-- % Complete  328\\644-0.jpg  \n",
       "3         NaN             NaN  328\\656-0.jpg  \n",
       "4         NaN             NaN  328\\720-0.jpg  \n",
       "5         NaN             NaN  328\\779-0.jpg  \n",
       "6         NaN             NaN  328\\780-0.jpg  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get rid of first two rows\n",
    "data = data[2:]\n",
    "data = data[data['SIGN OUT'].notna()]\n",
    "data = data[data['POOR QUALITY'].notna()]\n",
    "data['ext'] = data['Folder'] + '\\\\' + data['File']\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3aea399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4996 entries, 2 to 5001\n",
      "Data columns (total 19 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   id                          4996 non-null   object\n",
      " 1   manifestid                  4996 non-null   object\n",
      " 2   documentid                  4996 non-null   object\n",
      " 3   Full                        4996 non-null   object\n",
      " 4   uploaddatetimejsonmetadata  4996 non-null   object\n",
      " 5   Folder                      4996 non-null   object\n",
      " 6   File                        4996 non-null   object\n",
      " 7   LABEL                       4996 non-null   object\n",
      " 8   SIGN OUT                    4996 non-null   object\n",
      " 9   ALLIGATOR                   4970 non-null   object\n",
      " 10  CATEGORY 1                  4865 non-null   object\n",
      " 11  CATEGORY 2                  493 non-null    object\n",
      " 12  CATEGORY 3                  65 non-null     object\n",
      " 13  POOR QUALITY                4996 non-null   object\n",
      " 14  NOTES                       1268 non-null   object\n",
      " 15  onpremfilepathjsonmetadata  4996 non-null   object\n",
      " 16  Unnamed: 16                 1 non-null      object\n",
      " 17  Unnamed: 17                 1 non-null      object\n",
      " 18  ext                         4996 non-null   object\n",
      "dtypes: object(19)\n",
      "memory usage: 780.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694e81ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many everyone has labeled\n",
    "data[data['SIGN OUT'].notna()].LABEL.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e490e36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['SIGN OUT'].notna()].LABEL.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe460b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['LABEL', 'SIGN OUT']).size().reset_index(name='Count').sort_values('Count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ed9f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SIGN OUT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db44e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.ALLIGATOR.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6f3ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Full.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7c5340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of case problems\n",
    "data['CATEGORY 1'] = data['CATEGORY 1'].str.lower()\n",
    "data['CATEGORY 1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971933f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of case problems\n",
    "data['CATEGORY 2'] = data['CATEGORY 2'].str.lower()\n",
    "data['CATEGORY 2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0996c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of case problems\n",
    "data['CATEGORY 3'] = data['CATEGORY 3'].str.lower()\n",
    "data['CATEGORY 3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc7a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column that shows if a picture is a duplicate of another\n",
    "data['DUPLICATE'] = data['CATEGORY 1'].str.contains('duplicate', case=False, regex = False)\n",
    "data.DUPLICATE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4d0326",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['POOR QUALITY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958a0044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a df for those that are poor quality, high quality, alligator and not alligator freight and full and not full\n",
    "poor_df = data[data['POOR QUALITY'] == True]\n",
    "good_df = data[data['POOR QUALITY'] == False]\n",
    "\n",
    "alligator_df = data[data['ALLIGATOR'] == True]\n",
    "non_alligator_df = data[data['ALLIGATOR'] == False]\n",
    "\n",
    "full_df = data[data['Full'] == 'TRUE']\n",
    "not_full_df = data[data['Full'] == 'FALSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88db16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(poor_df.shape)\n",
    "print(good_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486c8c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(alligator_df.shape)\n",
    "print(non_alligator_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c896a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_df.shape)\n",
    "print(not_full_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7810d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pictures that show there needs to be an airbag\n",
    "airbag_df = data[data['CATEGORY 1'].str.contains('airbag', case=False, regex=False) | \n",
    "                 data['CATEGORY 2'].str.contains('airbag', case=False, regex=False) |\n",
    "                 data['CATEGORY 3'].str.contains('airbag', case=False, regex=False)]\n",
    "\n",
    "# Pictures that don't need airbag\n",
    "non_airbag_df = data[~data.index.isin(airbag_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f38972",
   "metadata": {},
   "outputs": [],
   "source": [
    "airbag_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8572b5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_airbag_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866a2b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pictures that show there needs to be a return to level\n",
    "level_df = data[data['CATEGORY 1'].str.contains('level', case=False, regex=False) | \n",
    "                 data['CATEGORY 2'].str.contains('level', case=False, regex=False) |\n",
    "                 data['CATEGORY 3'].str.contains('level', case=False, regex=False)]\n",
    "\n",
    "# Pictures that don't need return to level\n",
    "non_level_df = data[~data.index.isin(level_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b6acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec70fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_level_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bc9d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pictures that show there needs to be a restack\n",
    "restack_df = data[data['CATEGORY 1'].str.contains('restack', case=False, regex=False) | \n",
    "                 data['CATEGORY 2'].str.contains('restack', case=False, regex=False) |\n",
    "                 data['CATEGORY 3'].str.contains('restack', case=False, regex=False)]\n",
    "\n",
    "# Pictures that don't need a restack\n",
    "non_restack_df = data[~data.index.isin(restack_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad68cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "restack_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72081fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_restack_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab81bc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pictures that pass\n",
    "pass_df = data[data['CATEGORY 1'].str.contains('pass', case=False, regex=False) | \n",
    "                 data['CATEGORY 2'].str.contains('pass', case=False, regex=False) |\n",
    "                 data['CATEGORY 3'].str.contains('pass', case=False, regex=False)]\n",
    "\n",
    "# Pictures that don't pass\n",
    "non_pass_df = data[~data.index.isin(pass_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ed6f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73c3b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_pass_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340e0977",
   "metadata": {},
   "source": [
    "# Model for Poor quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d208723d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set proportions:\n",
      "False    0.885453\n",
      "True     0.114547\n",
      "Name: POOR QUALITY, dtype: float64\n",
      "\n",
      "Test set proportions:\n",
      "False    0.886\n",
      "True     0.114\n",
      "Name: POOR QUALITY, dtype: float64\n",
      "\n",
      "Val set proportions:\n",
      "False    0.885\n",
      "True     0.115\n",
      "Name: POOR QUALITY, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming your dataframe is called 'df'\n",
    "# Splitting the dataframe into train and test sets while stratifying based on 'Full' column\n",
    "training, test_df = train_test_split(data, test_size=0.2, stratify=data['POOR QUALITY'])\n",
    "train_df, val_df = train_test_split(training, test_size=0.15, stratify=training['POOR QUALITY'])\n",
    "\n",
    "# Checking the proportions of True and False values in the 'Full' column for train and test sets\n",
    "train_counts = train_df['POOR QUALITY'].value_counts(normalize=True)\n",
    "test_counts = test_df['POOR QUALITY'].value_counts(normalize=True)\n",
    "val_counts = val_df['POOR QUALITY'].value_counts(normalize=True)\n",
    "print(\"Train set proportions:\")\n",
    "print(train_counts)\n",
    "print(\"\\nTest set proportions:\")\n",
    "print(test_counts)\n",
    "print(\"\\nVal set proportions:\")\n",
    "print(val_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec1217eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['POOR QUALITY'] = train_df['POOR QUALITY'].map({True:'True', False:'False'})\n",
    "val_df['POOR QUALITY'] = val_df['POOR QUALITY'].map({True:'True', False:'False'})\n",
    "test_df['POOR QUALITY'] = test_df['POOR QUALITY'].map({True:'True', False:'False'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7fc6388",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"C:\\\\Users\\\\tfurr\\\\OneDrive\\\\Documents\\\\School\\\\UChicago\\\\Spring 2023\\\\MSCA Capstone 1\\\\Code Files\\\\Photos_all\\\\\"\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "   # rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2)\n",
    "    #horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0ffe136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3369 validated image filenames belonging to 2 classes.\n",
      "Found 594 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tfurr\\anaconda\\lib\\site-packages\\keras\\preprocessing\\image.py:1137: UserWarning: Found 27 invalid image filename(s) in x_col=\"ext\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tfurr\\anaconda\\lib\\site-packages\\keras\\preprocessing\\image.py:1137: UserWarning: Found 6 invalid image filename(s) in x_col=\"ext\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 994 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tfurr\\anaconda\\lib\\site-packages\\keras\\preprocessing\\image.py:1137: UserWarning: Found 6 invalid image filename(s) in x_col=\"ext\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=image_dir,\n",
    "    x_col='ext',\n",
    "    y_col='POOR QUALITY',\n",
    "    target_size=(224,224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\")\n",
    "\n",
    "val_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=image_dir,\n",
    "    x_col='ext',\n",
    "    y_col='POOR QUALITY',\n",
    "    target_size=(224,224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\")\n",
    "\n",
    "test_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=image_dir,\n",
    "    x_col='ext',\n",
    "    y_col='POOR QUALITY',\n",
    "    target_size=(224,224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b6399c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dimension = (224, 224, 3)\n",
    "\n",
    "metrics1 = [TruePositives(), FalsePositives(), TrueNegatives(), FalseNegatives(), BinaryAccuracy(), Precision(), Recall(), Accuracy(), AUC()]\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Resizing(224, 224),\n",
    "    layers.Rescaling(1./255),\n",
    "    layers.RandomFlip(mode=\"horizontal_and_vertical\"),\n",
    "    layers.RandomTranslation(height_factor=0.2, width_factor=0.2),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomContrast(factor=0.2),\n",
    "    layers.RandomBrightness(factor=0.2),\n",
    "    \n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_dimension),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dense(250, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=metrics1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50b2dfe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "106/106 [==============================] - 793s 7s/step - loss: 13.4495 - true_positives: 5.0000 - false_positives: 24.0000 - true_negatives: 2958.0000 - false_negatives: 382.0000 - binary_accuracy: 0.8795 - precision: 0.1724 - recall: 0.0129 - accuracy: 0.0594 - auc: 0.5116 - val_loss: 0.5690 - val_true_positives: 0.0000e+00 - val_false_positives: 0.0000e+00 - val_true_negatives: 525.0000 - val_false_negatives: 69.0000 - val_binary_accuracy: 0.8838 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_auc: 0.5185\n",
      "Epoch 2/2\n",
      "106/106 [==============================] - 772s 7s/step - loss: 0.4124 - true_positives: 0.0000e+00 - false_positives: 0.0000e+00 - true_negatives: 2982.0000 - false_negatives: 387.0000 - binary_accuracy: 0.8851 - precision: 0.0000e+00 - recall: 0.0000e+00 - accuracy: 0.0000e+00 - auc: 0.4676 - val_loss: 0.4646 - val_true_positives: 0.0000e+00 - val_false_positives: 0.0000e+00 - val_true_negatives: 525.0000 - val_false_negatives: 69.0000 - val_binary_accuracy: 0.8838 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_auc: 0.5170\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, epochs=2, validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32777152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Metrics:\n",
      "loss: 0.412374883890152\n",
      "true_positives: 0.0\n",
      "false_positives: 0.0\n",
      "true_negatives: 2982.0\n",
      "false_negatives: 387.0\n",
      "binary_accuracy: 0.8851290941238403\n",
      "precision: 0.0\n",
      "recall: 0.0\n",
      "accuracy: 0.0\n",
      "auc: 0.4675659239292145\n",
      "val_loss: 0.46460995078086853\n",
      "val_true_positives: 0.0\n",
      "val_false_positives: 0.0\n",
      "val_true_negatives: 525.0\n",
      "val_false_negatives: 69.0\n",
      "val_binary_accuracy: 0.8838383555412292\n",
      "val_precision: 0.0\n",
      "val_recall: 0.0\n",
      "val_accuracy: 0.0\n",
      "val_auc: 0.5170462131500244\n"
     ]
    }
   ],
   "source": [
    "final_metrics = history.history\n",
    "\n",
    "print(\"Final Metrics:\")\n",
    "for metric_name, metric_values in final_metrics.items():\n",
    "    print(f\"{metric_name}: {metric_values[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b72b645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 184s 6s/step - loss: 0.4499 - true_positives: 0.0000e+00 - false_positives: 0.0000e+00 - true_negatives: 880.0000 - false_negatives: 114.0000 - binary_accuracy: 0.8853 - precision: 0.0000e+00 - recall: 0.0000e+00 - accuracy: 0.0000e+00 - auc: 0.5871\n"
     ]
    }
   ],
   "source": [
    "test_metrics = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0262acee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Metrics:\n",
      "loss: 0.44988328218460083\n",
      "true_positives: 0.0\n",
      "false_positives: 0.0\n",
      "true_negatives: 880.0\n",
      "false_negatives: 114.0\n",
      "binary_accuracy: 0.8853118419647217\n",
      "precision: 0.0\n",
      "recall: 0.0\n",
      "accuracy: 0.0\n",
      "auc: 0.5871361494064331\n"
     ]
    }
   ],
   "source": [
    "names = model.metrics_names\n",
    "values = test_metrics\n",
    "\n",
    "print(\"Final Metrics:\")\n",
    "for metric_name, metric_value in zip(names, values):\n",
    "    print(f\"{metric_name}: {metric_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34bb5ac",
   "metadata": {},
   "source": [
    "## Model with additional conv2d, batch normalization and regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2898f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_dimension = (224, 224, 3)\n",
    "\n",
    "model1 = Sequential([\n",
    "    layers.Resizing(224, 224),\n",
    "    layers.Rescaling(1./255),\n",
    "    layers.RandomFlip(mode=\"horizontal_and_vertical\"),\n",
    "    layers.RandomTranslation(height_factor=0.2, width_factor=0.2),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomContrast(factor=0.2),\n",
    "    layers.RandomBrightness(factor=0.2),\n",
    "    \n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_dimension),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dense(250, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50991b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.fit(train_generator, epochs=5, validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7d0163",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c996055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afccbcde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7652d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e9ebf4f",
   "metadata": {},
   "source": [
    "# Model with different weights on the positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6080e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a18b99a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dimension = (224, 224, 3)\n",
    "\n",
    "metrics1 = [TruePositives(), FalsePositives(), TrueNegatives(), FalseNegatives(), BinaryAccuracy(), Precision(), Recall(), Accuracy(), AUC()]\n",
    "\n",
    "weighted_model = Sequential([\n",
    "    layers.Resizing(224, 224),\n",
    "    layers.Rescaling(1./255),\n",
    "    layers.RandomFlip(mode=\"horizontal_and_vertical\"),\n",
    "    layers.RandomTranslation(height_factor=0.2, width_factor=0.2),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomContrast(factor=0.2),\n",
    "    layers.RandomBrightness(factor=0.2),\n",
    "    \n",
    "    layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=input_dimension),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dense(250, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "])\n",
    "\n",
    "weighted_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=metrics1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a19d56a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9821400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg, pos = np.bincount(data['POOR QUALITY'])\n",
    "total = neg + pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a106ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5646473779385172, 2.1835664335664338)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_for_False = (1 / neg) * (total / 2.0)\n",
    "weight_for_True = (1 / pos/2) * (total / 2.0)\n",
    "\n",
    "weight_for_False, weight_for_True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97387aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {0:weight_for_False, 1: weight_for_True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e5ac23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "106/106 [==============================] - 845s 8s/step - loss: 21.6569 - true_positives_1: 23.0000 - false_positives_1: 201.0000 - true_negatives_1: 2781.0000 - false_negatives_1: 364.0000 - binary_accuracy: 0.8323 - precision_1: 0.1027 - recall_1: 0.0594 - accuracy: 0.0285 - auc_1: 0.4942 - val_loss: 0.6605 - val_true_positives_1: 0.0000e+00 - val_false_positives_1: 0.0000e+00 - val_true_negatives_1: 525.0000 - val_false_negatives_1: 69.0000 - val_binary_accuracy: 0.8838 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_auc_1: 0.4478\n",
      "Epoch 2/2\n",
      "106/106 [==============================] - 368s 3s/step - loss: 0.4904 - true_positives_1: 6.0000 - false_positives_1: 47.0000 - true_negatives_1: 2935.0000 - false_negatives_1: 381.0000 - binary_accuracy: 0.8730 - precision_1: 0.1132 - recall_1: 0.0155 - accuracy: 0.0000e+00 - auc_1: 0.4995 - val_loss: 0.5847 - val_true_positives_1: 0.0000e+00 - val_false_positives_1: 0.0000e+00 - val_true_negatives_1: 525.0000 - val_false_negatives_1: 69.0000 - val_binary_accuracy: 0.8838 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_auc_1: 0.4912\n"
     ]
    }
   ],
   "source": [
    "weighted_history = weighted_model.fit(train_generator, epochs=2, validation_data=val_generator, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8b69106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Metrics:\n",
      "loss: 0.4904424250125885\n",
      "true_positives_1: 6.0\n",
      "false_positives_1: 47.0\n",
      "true_negatives_1: 2935.0\n",
      "false_negatives_1: 381.0\n",
      "binary_accuracy: 0.872959315776825\n",
      "precision_1: 0.11320754885673523\n",
      "recall_1: 0.01550387591123581\n",
      "accuracy: 0.0\n",
      "auc_1: 0.49954813718795776\n",
      "val_loss: 0.584652841091156\n",
      "val_true_positives_1: 0.0\n",
      "val_false_positives_1: 0.0\n",
      "val_true_negatives_1: 525.0\n",
      "val_false_negatives_1: 69.0\n",
      "val_binary_accuracy: 0.8838383555412292\n",
      "val_precision_1: 0.0\n",
      "val_recall_1: 0.0\n",
      "val_accuracy: 0.0\n",
      "val_auc_1: 0.4911663234233856\n"
     ]
    }
   ],
   "source": [
    "weighted_final_metrics = weighted_history.history\n",
    "\n",
    "print(\"Final Metrics:\")\n",
    "for metric_name, metric_values in weighted_final_metrics.items():\n",
    "    print(f\"{metric_name}: {metric_values[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a101fd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 53s 2s/step - loss: 0.5844 - true_positives_1: 0.0000e+00 - false_positives_1: 0.0000e+00 - true_negatives_1: 880.0000 - false_negatives_1: 114.0000 - binary_accuracy: 0.8853 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - accuracy: 0.0000e+00 - auc_1: 0.4906\n"
     ]
    }
   ],
   "source": [
    "weighted_test_metrics = weighted_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d6892cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Metrics:\n",
      "loss: 0.5843783617019653\n",
      "true_positives_1: 0.0\n",
      "false_positives_1: 0.0\n",
      "true_negatives_1: 880.0\n",
      "false_negatives_1: 114.0\n",
      "binary_accuracy: 0.8853118419647217\n",
      "precision_1: 0.0\n",
      "recall_1: 0.0\n",
      "accuracy: 0.0\n",
      "auc_1: 0.49058014154434204\n"
     ]
    }
   ],
   "source": [
    "names = weighted_model.metrics_names\n",
    "values = weighted_test_metrics\n",
    "\n",
    "print(\"Final Metrics:\")\n",
    "for metric_name, metric_value in zip(names, values):\n",
    "    print(f\"{metric_name}: {metric_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a4931c",
   "metadata": {},
   "source": [
    "### Biased Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251a1056",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_bias = np.log([pos/neg])\n",
    "initial_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e6fda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dimension = (224, 224, 3)\n",
    "\n",
    "metrics1 = [TruePositives(), FalsePositives(), TrueNegatives(), FalseNegatives(), BinaryAccuracy(), Precision(), Recall(), Accuracy(), AUC()]\n",
    "\n",
    "output_bias = tf.keras.initializers.Constant(initial_bias)\n",
    "\n",
    "biased_model = Sequential([\n",
    "    layers.Resizing(224, 224),\n",
    "    layers.Rescaling(1./255),\n",
    "    layers.RandomFlip(mode=\"horizontal_and_vertical\"),\n",
    "    layers.RandomTranslation(height_factor=0.2, width_factor=0.2),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomContrast(factor=0.2),\n",
    "    layers.RandomBrightness(factor=0.2),\n",
    "    \n",
    "    layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=input_dimension),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dense(250, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    layers.Dense(1, activation='sigmoid', bias_initializer=output_bias)\n",
    "    \n",
    "])\n",
    "\n",
    "biased_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=metrics1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a42cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "biased_history = biased_model.fit(train_generator, epochs=5, validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9828e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics(biased_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c6826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "biased_test_metrics = biased_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a7f352",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = biased_model.metrics_names\n",
    "values = biased_test_metrics\n",
    "\n",
    "print(\"Final Metrics:\")\n",
    "for metric_name, metric_value in zip(names, values):\n",
    "    print(f\"{metric_name}: {metric_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf18082",
   "metadata": {},
   "source": [
    "### Run over a bunch of different model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cf8967",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_labels = data['POOR QUALITY']\n",
    "target_labels = target_labels.astype('bool')  # Convert to boolean type if needed\n",
    "\n",
    "# Handle missing or NaN values\n",
    "target_labels[pd.isna(target_labels)] = False\n",
    "\n",
    "class_weights = compute_class_weight(\"balanced\", classes=[False, True], y=target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d2db60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wdic = {0: class_weights[0], 1: class_weights[1]}\n",
    "wdic11 = {0: class_weights[0], 1: class_weights[1]/1.1}\n",
    "wdic12 = {0: class_weights[0], 1: class_weights[1]/1.2}\n",
    "wdic13 = {0: class_weights[0], 1: class_weights[1]/1.3}\n",
    "wdic14 = {0: class_weights[0], 1: class_weights[1]/1.4}\n",
    "wdic15 = {0: class_weights[0], 1: class_weights[1]/1.5}\n",
    "wdic16 = {0: class_weights[0], 1: class_weights[1]/1.6}\n",
    "wdic17 = {0: class_weights[0], 1: class_weights[1]/1.7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12fc061",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_list = [wdic, wdic11, wdic12, wdic13, wdic14, wdic15, wdic16, wdic17]\n",
    "class_weights_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d56140",
   "metadata": {},
   "source": [
    "### Class weights based on what is given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b586a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dimension = (224, 224, 3)\n",
    "\n",
    "metrics1 = [TruePositives(), FalsePositives(), TrueNegatives(), FalseNegatives(), BinaryAccuracy(), Precision(), Recall(), Accuracy(), AUC()]\n",
    "\n",
    "model_weight = Sequential([\n",
    "    layers.Resizing(224, 224),\n",
    "    layers.Rescaling(1./255),\n",
    "    layers.RandomFlip(mode=\"horizontal_and_vertical\"),\n",
    "    layers.RandomTranslation(height_factor=0.2, width_factor=0.2),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomContrast(factor=0.2),\n",
    "    layers.RandomBrightness(factor=0.2),\n",
    "    \n",
    "    layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=input_dimension),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dense(250, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "])\n",
    "\n",
    "model_weight.compile(optimizer='adam', loss='binary_crossentropy', metrics=metrics1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc369fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_weight = model_weight.fit(train_generator, epochs=5, validation_data=val_generator, class_weight=wdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f679f625",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics(hist_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5299797",
   "metadata": {},
   "source": [
    "### Weights divided by 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed9b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dimension = (224, 224, 3)\n",
    "\n",
    "metrics1 = [TruePositives(), FalsePositives(), TrueNegatives(), FalseNegatives(), BinaryAccuracy(), Precision(), Recall(), Accuracy(), AUC()]\n",
    "\n",
    "model12 = Sequential([\n",
    "    layers.Resizing(224, 224),\n",
    "    layers.Rescaling(1./255),\n",
    "    layers.RandomFlip(mode=\"horizontal_and_vertical\"),\n",
    "    layers.RandomTranslation(height_factor=0.2, width_factor=0.2),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomContrast(factor=0.2),\n",
    "    layers.RandomBrightness(factor=0.2),\n",
    "    \n",
    "    layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=input_dimension),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dense(250, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "])\n",
    "\n",
    "model12.compile(optimizer='adam', loss='binary_crossentropy', metrics=metrics1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd87ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "history12 = model12.fit(train_generator, epochs=5, validation_data=val_generator, class_weight=wdic12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5c6c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics(history12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3966a68",
   "metadata": {},
   "source": [
    "### Weights divided by 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12806d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dimension = (224, 224, 3)\n",
    "\n",
    "metrics1 = [TruePositives(), FalsePositives(), TrueNegatives(), FalseNegatives(), BinaryAccuracy(), Precision(), Recall(), Accuracy(), AUC()]\n",
    "\n",
    "model15 = Sequential([\n",
    "    layers.Resizing(224, 224),\n",
    "    layers.Rescaling(1./255),\n",
    "    layers.RandomFlip(mode=\"horizontal_and_vertical\"),\n",
    "    layers.RandomTranslation(height_factor=0.2, width_factor=0.2),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomContrast(factor=0.2),\n",
    "    layers.RandomBrightness(factor=0.2),\n",
    "    \n",
    "    layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=input_dimension),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dense(250, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "])\n",
    "\n",
    "model15.compile(optimizer='adam', loss='binary_crossentropy', metrics=metrics1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1396e89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history15 = model15.fit(train_generator, epochs=5, validation_data=val_generator, class_weight=wdic15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bc4f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics(history15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f61475",
   "metadata": {},
   "source": [
    "# VGG16 Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84090810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "metrics1 = [TruePositives(), FalsePositives(), TrueNegatives(), FalseNegatives(), BinaryAccuracy(), Precision(), Recall(), Accuracy(), AUC()]\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable= False\n",
    "\n",
    "x = base_model.output\n",
    "# Apply the layers from model15 on top of the base model\n",
    "x = layers.Resizing(224, 224)(x)\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "x = layers.RandomFlip(mode=\"horizontal_and_vertical\")(x)\n",
    "x = layers.RandomTranslation(height_factor=0.2, width_factor=0.2)(x)\n",
    "x = layers.RandomRotation(0.2)(x)\n",
    "#x = layers.RandomContrast(factor=0.2)(x)\n",
    "x = layers.RandomBrightness(factor=0.2)(x)\n",
    "\n",
    "x = layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(224, 224, 3))(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dense(250, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "predictions = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the final model\n",
    "vgg_model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d820e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=metrics1)\n",
    "vgg_model.fit(train_generator, epochs=5, validation_data=val_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
