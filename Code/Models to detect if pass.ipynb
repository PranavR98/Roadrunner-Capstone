{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8055e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.metrics import TruePositives, FalsePositives, TrueNegatives, FalseNegatives\n",
    "from keras.optimizers import SGD,RMSprop,adam\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "#from keras.applications.vgg16 import VGG16\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dabeb733",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\tfurr\\\\OneDrive\\\\Documents\\\\School\\\\UChicago\\\\Spring 2023\\\\MSCA Capstone 1\\\\Code Files\\\\Working Labeling Checklist with Dummy Variables - Working Labeling Checklist with Dummy Variables.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff56d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d548edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.ALLIGATOR.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9a8121",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Full.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8392c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['CATEGORY 1'] = data['CATEGORY 1'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb4e376",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['CATEGORY 1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d288177",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['is_pass'] = data['CATEGORY 1'].astype(str).apply(lambda x: 1 if 'pass' in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93c2795",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e2af46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2842\n",
       "1    2158\n",
       "Name: is_pass, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.is_pass.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40862722",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.is_pass = data.is_pass.map({0:'False', 1:'True'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d96d7618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2842\n",
       "True     2158\n",
       "Name: is_pass, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.is_pass.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6af47a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set proportions:\n",
      "False    0.568529\n",
      "True     0.431471\n",
      "Name: is_pass, dtype: float64\n",
      "\n",
      "Test set proportions:\n",
      "False    0.568\n",
      "True     0.432\n",
      "Name: is_pass, dtype: float64\n",
      "\n",
      "Val set proportions:\n",
      "False    0.568333\n",
      "True     0.431667\n",
      "Name: is_pass, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "training, test_df = train_test_split(data, test_size=0.2, stratify=data['is_pass'])\n",
    "train_df, val_df = train_test_split(training, test_size=0.15, stratify=training['is_pass'])\n",
    "\n",
    "# Checking the proportions of True and False values in the 'Full' column for train and test sets\n",
    "train_counts = train_df['is_pass'].value_counts(normalize=True)\n",
    "test_counts = test_df['is_pass'].value_counts(normalize=True)\n",
    "val_counts = val_df['is_pass'].value_counts(normalize=True)\n",
    "print(\"Train set proportions:\")\n",
    "print(train_counts)\n",
    "print(\"\\nTest set proportions:\")\n",
    "print(test_counts)\n",
    "print(\"\\nVal set proportions:\")\n",
    "print(val_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a789749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"C:\\\\Users\\\\tfurr\\\\OneDrive\\\\Documents\\\\School\\\\UChicago\\\\Spring 2023\\\\MSCA Capstone 1\\\\Code Files\\\\Photos_all\\\\\"\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "   # rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2)\n",
    "    #horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feeeff98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3372 validated image filenames belonging to 2 classes.\n",
      "Found 594 validated image filenames belonging to 2 classes.\n",
      "Found 995 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tfurr\\anaconda\\lib\\site-packages\\keras\\preprocessing\\image.py:1137: UserWarning: Found 28 invalid image filename(s) in x_col=\"ext\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tfurr\\anaconda\\lib\\site-packages\\keras\\preprocessing\\image.py:1137: UserWarning: Found 6 invalid image filename(s) in x_col=\"ext\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tfurr\\anaconda\\lib\\site-packages\\keras\\preprocessing\\image.py:1137: UserWarning: Found 5 invalid image filename(s) in x_col=\"ext\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=image_dir,\n",
    "    x_col='ext',\n",
    "    y_col='is_pass',\n",
    "    target_size=(224,224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\")\n",
    "\n",
    "val_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=image_dir,\n",
    "    x_col='ext',\n",
    "    y_col='is_pass',\n",
    "    target_size=(224,224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\")\n",
    "\n",
    "test_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=image_dir,\n",
    "    x_col='ext',\n",
    "    y_col='is_pass',\n",
    "    target_size=(224,224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42ec66a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dimension = (224, 224, 3)\n",
    "\n",
    "metrics1 = [TruePositives(), FalsePositives(), TrueNegatives(), FalseNegatives()]\n",
    "\n",
    "first_model = Sequential([\n",
    "    layers.Resizing(224, 224),\n",
    "    layers.Rescaling(1./255),\n",
    "    layers.RandomFlip(mode=\"horizontal_and_vertical\"),\n",
    "    layers.RandomTranslation(height_factor=0.2, width_factor=0.2),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomContrast(factor=0.2),\n",
    "    layers.RandomBrightness(factor=0.2),\n",
    "    \n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_dimension),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.1),\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.15),\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dense(250, activation='relu'),\n",
    "    \n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "first_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=metrics1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2ec51f0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "106/106 [==============================] - 386s 4s/step - loss: 11.0918 - true_positives: 200.0000 - false_positives: 252.0000 - true_negatives: 1664.0000 - false_negatives: 1256.0000 - val_loss: 0.6887 - val_true_positives: 0.0000e+00 - val_false_positives: 0.0000e+00 - val_true_negatives: 338.0000 - val_false_negatives: 256.0000\n",
      "Epoch 2/4\n",
      "106/106 [==============================] - 523s 5s/step - loss: 0.6878 - true_positives: 70.0000 - false_positives: 97.0000 - true_negatives: 1819.0000 - false_negatives: 1386.0000 - val_loss: 0.6852 - val_true_positives: 0.0000e+00 - val_false_positives: 0.0000e+00 - val_true_negatives: 338.0000 - val_false_negatives: 256.0000\n",
      "Epoch 3/4\n",
      "106/106 [==============================] - 763s 7s/step - loss: 0.6854 - true_positives: 8.0000 - false_positives: 11.0000 - true_negatives: 1905.0000 - false_negatives: 1448.0000 - val_loss: 0.6843 - val_true_positives: 0.0000e+00 - val_false_positives: 0.0000e+00 - val_true_negatives: 338.0000 - val_false_negatives: 256.0000\n",
      "Epoch 4/4\n",
      "  7/106 [>.............................] - ETA: 10:47 - loss: 0.6878 - true_positives: 0.0000e+00 - false_positives: 0.0000e+00 - true_negatives: 125.0000 - false_negatives: 99.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mfirst_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = first_model.fit(train_generator, epochs=4, validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c993b9f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m final_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal Metrics:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric_name, metric_values \u001b[38;5;129;01min\u001b[39;00m final_metrics\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "final_metrics = history.history\n",
    "\n",
    "print(\"Final Metrics:\")\n",
    "for metric_name, metric_values in final_metrics.items():\n",
    "    print(f\"{metric_name}: {metric_values[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fed8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = first_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e931cd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = first_model.metrics_names\n",
    "values = test_metrics\n",
    "\n",
    "print(\"Final Metrics:\")\n",
    "for metric_name, metric_value in zip(names, values):\n",
    "    print(f\"{metric_name}: {metric_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a53842",
   "metadata": {},
   "source": [
    "# Model balanced with Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "255f9965",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight('balanced', classes=[\"False\",\"True\"], y=train_df['is_pass'])\n",
    "class_weights = {0: class_weights[0], 1: class_weights[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0ad7fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dimension = (224, 224, 3)\n",
    "\n",
    "metrics1 = [TruePositives(), FalsePositives(), TrueNegatives(), FalseNegatives()]\n",
    "\n",
    "balanced_model = Sequential([\n",
    "    layers.Resizing(224, 224),\n",
    "    layers.Rescaling(1./255),\n",
    "    layers.RandomFlip(mode=\"horizontal_and_vertical\"),\n",
    "    layers.RandomTranslation(height_factor=0.2, width_factor=0.2),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomContrast(factor=0.2),\n",
    "    layers.RandomBrightness(factor=0.2),\n",
    "    \n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_dimension),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    #layers.Dropout(0.5),\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dense(128, activation='relu'),\n",
    "    #layers.Dropout(0.5),\n",
    "    \n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "balanced_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=metrics1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb79db77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "106/106 [==============================] - 785s 7s/step - loss: 10.8361 - true_positives_3: 1002.0000 - false_positives_3: 1279.0000 - true_negatives_3: 637.0000 - false_negatives_3: 454.0000 - val_loss: 0.6936 - val_true_positives_3: 207.0000 - val_false_positives_3: 284.0000 - val_true_negatives_3: 54.0000 - val_false_negatives_3: 49.0000\n",
      "Epoch 2/5\n",
      "106/106 [==============================] - 740s 7s/step - loss: 0.6933 - true_positives_3: 1456.0000 - false_positives_3: 1916.0000 - true_negatives_3: 0.0000e+00 - false_negatives_3: 0.0000e+00 - val_loss: 0.6935 - val_true_positives_3: 195.0000 - val_false_positives_3: 279.0000 - val_true_negatives_3: 59.0000 - val_false_negatives_3: 61.0000\n",
      "Epoch 3/5\n",
      "106/106 [==============================] - 752s 7s/step - loss: 0.6932 - true_positives_3: 1456.0000 - false_positives_3: 1916.0000 - true_negatives_3: 0.0000e+00 - false_negatives_3: 0.0000e+00 - val_loss: 0.6935 - val_true_positives_3: 179.0000 - val_false_positives_3: 256.0000 - val_true_negatives_3: 82.0000 - val_false_negatives_3: 77.0000\n",
      "Epoch 4/5\n",
      "106/106 [==============================] - 752s 7s/step - loss: 0.6932 - true_positives_3: 1456.0000 - false_positives_3: 1916.0000 - true_negatives_3: 0.0000e+00 - false_negatives_3: 0.0000e+00 - val_loss: 0.6933 - val_true_positives_3: 126.0000 - val_false_positives_3: 190.0000 - val_true_negatives_3: 148.0000 - val_false_negatives_3: 130.0000\n",
      "Epoch 5/5\n",
      "106/106 [==============================] - 758s 7s/step - loss: 0.6932 - true_positives_3: 1456.0000 - false_positives_3: 1916.0000 - true_negatives_3: 0.0000e+00 - false_negatives_3: 0.0000e+00 - val_loss: 0.6933 - val_true_positives_3: 124.0000 - val_false_positives_3: 173.0000 - val_true_negatives_3: 165.0000 - val_false_negatives_3: 132.0000\n"
     ]
    }
   ],
   "source": [
    "balanced_history = balanced_model.fit(train_generator, epochs=5, batch_size=32, validation_data=val_generator, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96b05be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6031483015741508"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1456/(1456+(0.5*(1916)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5c16e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 175s 5s/step - loss: 0.6930 - true_positives_3: 233.0000 - false_positives_3: 286.0000 - true_negatives_3: 280.0000 - false_negatives_3: 196.0000\n"
     ]
    }
   ],
   "source": [
    "test_metrics_balanced = balanced_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd8cfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = balanced_model.metrics_names\n",
    "values = test_metrics_balanced\n",
    "\n",
    "print(\"Final Metrics:\")\n",
    "for metric_name, metric_value in zip(names, values):\n",
    "    print(f\"{metric_name}: {metric_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7761f010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 167s 5s/step\n",
      "106/106 [==============================] - 273s 3s/step\n",
      "19/19 [==============================] - 40s 2s/step\n"
     ]
    }
   ],
   "source": [
    "preds = balanced_model.predict(test_generator)\n",
    "train_preds = balanced_model.predict(train_generator)\n",
    "val_preds = balanced_model.predict(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53664e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50086755],\n",
       "       [0.50007147],\n",
       "       [0.49992794],\n",
       "       [0.5008668 ],\n",
       "       [0.49946502],\n",
       "       [0.5012158 ],\n",
       "       [0.4993006 ],\n",
       "       [0.49887633],\n",
       "       [0.49762788],\n",
       "       [0.5009391 ],\n",
       "       [0.4994395 ],\n",
       "       [0.4965839 ],\n",
       "       [0.4994374 ],\n",
       "       [0.50081354],\n",
       "       [0.5001744 ],\n",
       "       [0.49912655],\n",
       "       [0.5010349 ],\n",
       "       [0.500105  ],\n",
       "       [0.50121737],\n",
       "       [0.49993333],\n",
       "       [0.5004535 ],\n",
       "       [0.5006805 ],\n",
       "       [0.5003644 ],\n",
       "       [0.5005371 ],\n",
       "       [0.5012378 ],\n",
       "       [0.4997031 ],\n",
       "       [0.5002513 ],\n",
       "       [0.5011231 ],\n",
       "       [0.5008692 ],\n",
       "       [0.50100744],\n",
       "       [0.4988451 ],\n",
       "       [0.50092995],\n",
       "       [0.49741155],\n",
       "       [0.501031  ],\n",
       "       [0.5009427 ],\n",
       "       [0.50126535],\n",
       "       [0.4995309 ],\n",
       "       [0.49962997],\n",
       "       [0.49787784],\n",
       "       [0.499427  ],\n",
       "       [0.5005649 ],\n",
       "       [0.5013076 ],\n",
       "       [0.50083685],\n",
       "       [0.5007735 ],\n",
       "       [0.49640948],\n",
       "       [0.49969417],\n",
       "       [0.50100034],\n",
       "       [0.5006718 ],\n",
       "       [0.49927294],\n",
       "       [0.49852008],\n",
       "       [0.49884778],\n",
       "       [0.4989664 ],\n",
       "       [0.49995226],\n",
       "       [0.49979913],\n",
       "       [0.5009398 ],\n",
       "       [0.49886513],\n",
       "       [0.49962872],\n",
       "       [0.5013076 ],\n",
       "       [0.49821106],\n",
       "       [0.499284  ],\n",
       "       [0.5012498 ],\n",
       "       [0.5013076 ],\n",
       "       [0.50102174],\n",
       "       [0.50052   ],\n",
       "       [0.49983463],\n",
       "       [0.50118285],\n",
       "       [0.49988192],\n",
       "       [0.49992484],\n",
       "       [0.5012075 ],\n",
       "       [0.4984172 ],\n",
       "       [0.4994335 ],\n",
       "       [0.5010949 ],\n",
       "       [0.49644205],\n",
       "       [0.49964485],\n",
       "       [0.5012441 ],\n",
       "       [0.5002689 ],\n",
       "       [0.49989003],\n",
       "       [0.49895898],\n",
       "       [0.5007691 ],\n",
       "       [0.49860725],\n",
       "       [0.49830756],\n",
       "       [0.5008215 ],\n",
       "       [0.49831876],\n",
       "       [0.4985936 ],\n",
       "       [0.49922103],\n",
       "       [0.50119936],\n",
       "       [0.5013076 ],\n",
       "       [0.50039923],\n",
       "       [0.4986377 ],\n",
       "       [0.5004553 ],\n",
       "       [0.5011143 ],\n",
       "       [0.5002    ],\n",
       "       [0.49989048],\n",
       "       [0.50023204],\n",
       "       [0.4988654 ],\n",
       "       [0.49981356],\n",
       "       [0.49797216],\n",
       "       [0.49895394],\n",
       "       [0.49892223],\n",
       "       [0.49951363],\n",
       "       [0.5012592 ],\n",
       "       [0.49948683],\n",
       "       [0.5010958 ],\n",
       "       [0.4991319 ],\n",
       "       [0.49921176],\n",
       "       [0.49942467],\n",
       "       [0.5005111 ],\n",
       "       [0.5013076 ],\n",
       "       [0.49905053],\n",
       "       [0.500175  ],\n",
       "       [0.5009137 ],\n",
       "       [0.49905467],\n",
       "       [0.50060123],\n",
       "       [0.49949676],\n",
       "       [0.5010853 ],\n",
       "       [0.49990365],\n",
       "       [0.5013076 ],\n",
       "       [0.5013076 ],\n",
       "       [0.50033504],\n",
       "       [0.49919367],\n",
       "       [0.5013076 ],\n",
       "       [0.49806887],\n",
       "       [0.50000805],\n",
       "       [0.4991729 ],\n",
       "       [0.5001655 ],\n",
       "       [0.5013065 ],\n",
       "       [0.5005832 ],\n",
       "       [0.49978364],\n",
       "       [0.5001783 ],\n",
       "       [0.49942636],\n",
       "       [0.5006254 ],\n",
       "       [0.49982527],\n",
       "       [0.49982065],\n",
       "       [0.50088114],\n",
       "       [0.50045514],\n",
       "       [0.5009402 ],\n",
       "       [0.4971745 ],\n",
       "       [0.5001004 ],\n",
       "       [0.50076103],\n",
       "       [0.50059366],\n",
       "       [0.5002088 ],\n",
       "       [0.5001482 ],\n",
       "       [0.5010463 ],\n",
       "       [0.49862283],\n",
       "       [0.5013076 ],\n",
       "       [0.49959284],\n",
       "       [0.4989801 ],\n",
       "       [0.4991284 ],\n",
       "       [0.49986023],\n",
       "       [0.49889597],\n",
       "       [0.50110006],\n",
       "       [0.5007467 ],\n",
       "       [0.50116193],\n",
       "       [0.5004795 ],\n",
       "       [0.5003967 ],\n",
       "       [0.5012066 ],\n",
       "       [0.49972677],\n",
       "       [0.49824113],\n",
       "       [0.5013076 ],\n",
       "       [0.4984685 ],\n",
       "       [0.5013076 ],\n",
       "       [0.50097054],\n",
       "       [0.49950597],\n",
       "       [0.5000561 ],\n",
       "       [0.50020456],\n",
       "       [0.50130117],\n",
       "       [0.49982825],\n",
       "       [0.49914122],\n",
       "       [0.49832594],\n",
       "       [0.5009357 ],\n",
       "       [0.50110096],\n",
       "       [0.49911207],\n",
       "       [0.5003645 ],\n",
       "       [0.49765712],\n",
       "       [0.5004776 ],\n",
       "       [0.49937233],\n",
       "       [0.50007385],\n",
       "       [0.49950632],\n",
       "       [0.49970445],\n",
       "       [0.5013076 ],\n",
       "       [0.49993423],\n",
       "       [0.50055546],\n",
       "       [0.5003491 ],\n",
       "       [0.4978674 ],\n",
       "       [0.50113046],\n",
       "       [0.49928153],\n",
       "       [0.4989743 ],\n",
       "       [0.500359  ],\n",
       "       [0.500114  ],\n",
       "       [0.50072795],\n",
       "       [0.50126475],\n",
       "       [0.50034654],\n",
       "       [0.49951726],\n",
       "       [0.50061965],\n",
       "       [0.49862775],\n",
       "       [0.49983135],\n",
       "       [0.5009353 ],\n",
       "       [0.49960923],\n",
       "       [0.5000917 ],\n",
       "       [0.49706522],\n",
       "       [0.49981853],\n",
       "       [0.50108665],\n",
       "       [0.50047064],\n",
       "       [0.49999803],\n",
       "       [0.49941185],\n",
       "       [0.49826846],\n",
       "       [0.50044435],\n",
       "       [0.49898803],\n",
       "       [0.5001051 ],\n",
       "       [0.49851546],\n",
       "       [0.499524  ],\n",
       "       [0.49863735],\n",
       "       [0.5006714 ],\n",
       "       [0.49977946],\n",
       "       [0.5005372 ],\n",
       "       [0.49978155],\n",
       "       [0.49719718],\n",
       "       [0.49860772],\n",
       "       [0.50088495],\n",
       "       [0.49887764],\n",
       "       [0.50125736],\n",
       "       [0.5001206 ],\n",
       "       [0.5005358 ],\n",
       "       [0.49946862],\n",
       "       [0.5001109 ],\n",
       "       [0.49746093],\n",
       "       [0.50100976],\n",
       "       [0.5013076 ],\n",
       "       [0.49924913],\n",
       "       [0.5001466 ],\n",
       "       [0.5012274 ],\n",
       "       [0.499481  ],\n",
       "       [0.49698657],\n",
       "       [0.4981722 ],\n",
       "       [0.50039285],\n",
       "       [0.5004693 ],\n",
       "       [0.5013076 ],\n",
       "       [0.49826798],\n",
       "       [0.5003347 ],\n",
       "       [0.50049216],\n",
       "       [0.5002472 ],\n",
       "       [0.5000113 ],\n",
       "       [0.49949956],\n",
       "       [0.4990754 ],\n",
       "       [0.4984509 ],\n",
       "       [0.49938437],\n",
       "       [0.49988884],\n",
       "       [0.49937916],\n",
       "       [0.50059813],\n",
       "       [0.49846277],\n",
       "       [0.49951234],\n",
       "       [0.49845412],\n",
       "       [0.5012839 ],\n",
       "       [0.49907506],\n",
       "       [0.50093615],\n",
       "       [0.49812225],\n",
       "       [0.4999769 ],\n",
       "       [0.49833965],\n",
       "       [0.49921346],\n",
       "       [0.50096995],\n",
       "       [0.49980247],\n",
       "       [0.4993397 ],\n",
       "       [0.49985588],\n",
       "       [0.50106865],\n",
       "       [0.49947065],\n",
       "       [0.5013076 ],\n",
       "       [0.4994635 ],\n",
       "       [0.5013076 ],\n",
       "       [0.4981318 ],\n",
       "       [0.49752527],\n",
       "       [0.50081116],\n",
       "       [0.5012318 ],\n",
       "       [0.49864855],\n",
       "       [0.49914515],\n",
       "       [0.49906197],\n",
       "       [0.50051385],\n",
       "       [0.49984717],\n",
       "       [0.5004475 ],\n",
       "       [0.5000991 ],\n",
       "       [0.4992386 ],\n",
       "       [0.5012856 ],\n",
       "       [0.49808332],\n",
       "       [0.49948457],\n",
       "       [0.50025946],\n",
       "       [0.4998995 ],\n",
       "       [0.50057137],\n",
       "       [0.4998953 ],\n",
       "       [0.49984944],\n",
       "       [0.5012826 ],\n",
       "       [0.49948725],\n",
       "       [0.49793613],\n",
       "       [0.50123394],\n",
       "       [0.50125515],\n",
       "       [0.5012581 ],\n",
       "       [0.4997384 ],\n",
       "       [0.49938983],\n",
       "       [0.50057274],\n",
       "       [0.5012447 ],\n",
       "       [0.4997535 ],\n",
       "       [0.49922216],\n",
       "       [0.5009347 ],\n",
       "       [0.49776632],\n",
       "       [0.5004899 ],\n",
       "       [0.4998386 ],\n",
       "       [0.49374065],\n",
       "       [0.5012482 ],\n",
       "       [0.5003627 ],\n",
       "       [0.4991031 ],\n",
       "       [0.49942735],\n",
       "       [0.49814373],\n",
       "       [0.49987608],\n",
       "       [0.5013076 ],\n",
       "       [0.4997557 ],\n",
       "       [0.5011427 ],\n",
       "       [0.49852335],\n",
       "       [0.4988708 ],\n",
       "       [0.5002479 ],\n",
       "       [0.5003616 ],\n",
       "       [0.5001163 ],\n",
       "       [0.49982518],\n",
       "       [0.4988828 ],\n",
       "       [0.49997756],\n",
       "       [0.5013076 ],\n",
       "       [0.50025386],\n",
       "       [0.50022906],\n",
       "       [0.50005287],\n",
       "       [0.50082237],\n",
       "       [0.49886638],\n",
       "       [0.49912158],\n",
       "       [0.49861395],\n",
       "       [0.50008243],\n",
       "       [0.49971735],\n",
       "       [0.5013076 ],\n",
       "       [0.49958783],\n",
       "       [0.5001123 ],\n",
       "       [0.49996585],\n",
       "       [0.500534  ],\n",
       "       [0.5007294 ],\n",
       "       [0.50013894],\n",
       "       [0.4994253 ],\n",
       "       [0.4991745 ],\n",
       "       [0.49971125],\n",
       "       [0.50028443],\n",
       "       [0.5004764 ],\n",
       "       [0.49988234],\n",
       "       [0.49966553],\n",
       "       [0.49821177],\n",
       "       [0.49887732],\n",
       "       [0.5013076 ],\n",
       "       [0.5006203 ],\n",
       "       [0.5005832 ],\n",
       "       [0.50099117],\n",
       "       [0.49982202],\n",
       "       [0.50007623],\n",
       "       [0.49904963],\n",
       "       [0.5012332 ],\n",
       "       [0.49826765],\n",
       "       [0.50081307],\n",
       "       [0.5013076 ],\n",
       "       [0.50090754],\n",
       "       [0.5007296 ],\n",
       "       [0.49937853],\n",
       "       [0.49914485],\n",
       "       [0.5007296 ],\n",
       "       [0.49900642],\n",
       "       [0.5002503 ],\n",
       "       [0.49770647],\n",
       "       [0.49928743],\n",
       "       [0.50038767],\n",
       "       [0.5009218 ],\n",
       "       [0.5003449 ],\n",
       "       [0.5010378 ],\n",
       "       [0.49900013],\n",
       "       [0.5005238 ],\n",
       "       [0.5003567 ],\n",
       "       [0.49927023],\n",
       "       [0.50016373],\n",
       "       [0.50115514],\n",
       "       [0.4997365 ],\n",
       "       [0.49771947],\n",
       "       [0.4986067 ],\n",
       "       [0.5012415 ],\n",
       "       [0.49915752],\n",
       "       [0.49921894],\n",
       "       [0.50047404],\n",
       "       [0.49994197],\n",
       "       [0.50097185],\n",
       "       [0.49923557],\n",
       "       [0.4984165 ],\n",
       "       [0.49999753],\n",
       "       [0.50032824],\n",
       "       [0.5013076 ],\n",
       "       [0.497327  ],\n",
       "       [0.5000048 ],\n",
       "       [0.49998012],\n",
       "       [0.4988858 ],\n",
       "       [0.49964154],\n",
       "       [0.49906006],\n",
       "       [0.5009131 ],\n",
       "       [0.49986583],\n",
       "       [0.50065595],\n",
       "       [0.4987038 ],\n",
       "       [0.5013076 ],\n",
       "       [0.5003777 ],\n",
       "       [0.5005018 ],\n",
       "       [0.50080425],\n",
       "       [0.4975868 ],\n",
       "       [0.4993148 ],\n",
       "       [0.5013076 ],\n",
       "       [0.5000716 ],\n",
       "       [0.5013076 ],\n",
       "       [0.5009286 ],\n",
       "       [0.49738154],\n",
       "       [0.50123864],\n",
       "       [0.49891496],\n",
       "       [0.49879926],\n",
       "       [0.49843484],\n",
       "       [0.5013076 ],\n",
       "       [0.50119156],\n",
       "       [0.5000456 ],\n",
       "       [0.49952418],\n",
       "       [0.5001121 ],\n",
       "       [0.5010014 ],\n",
       "       [0.50046843],\n",
       "       [0.49969453],\n",
       "       [0.5013076 ],\n",
       "       [0.49997398],\n",
       "       [0.5013076 ],\n",
       "       [0.4996999 ],\n",
       "       [0.50030166],\n",
       "       [0.501178  ],\n",
       "       [0.500547  ],\n",
       "       [0.500642  ],\n",
       "       [0.50078243],\n",
       "       [0.49840102],\n",
       "       [0.50086963],\n",
       "       [0.4998348 ],\n",
       "       [0.49862397],\n",
       "       [0.49875897],\n",
       "       [0.50055295],\n",
       "       [0.49983987],\n",
       "       [0.50027585],\n",
       "       [0.50124216],\n",
       "       [0.5013076 ],\n",
       "       [0.500528  ],\n",
       "       [0.50055474],\n",
       "       [0.5011216 ],\n",
       "       [0.49967548],\n",
       "       [0.49999782],\n",
       "       [0.49939054],\n",
       "       [0.49923325],\n",
       "       [0.49634236],\n",
       "       [0.49967742],\n",
       "       [0.4998744 ],\n",
       "       [0.49960887],\n",
       "       [0.50039285],\n",
       "       [0.50017834],\n",
       "       [0.501198  ],\n",
       "       [0.4995735 ],\n",
       "       [0.5010501 ],\n",
       "       [0.4991397 ],\n",
       "       [0.5013076 ],\n",
       "       [0.49960914],\n",
       "       [0.49822786],\n",
       "       [0.5006844 ],\n",
       "       [0.49686605],\n",
       "       [0.50107133],\n",
       "       [0.5013038 ],\n",
       "       [0.50046074],\n",
       "       [0.49832815],\n",
       "       [0.50067604],\n",
       "       [0.49658108],\n",
       "       [0.4989301 ],\n",
       "       [0.49957886],\n",
       "       [0.49781826],\n",
       "       [0.5012056 ],\n",
       "       [0.49924484],\n",
       "       [0.49983668],\n",
       "       [0.50086427],\n",
       "       [0.4998772 ],\n",
       "       [0.50003767],\n",
       "       [0.5013076 ],\n",
       "       [0.49993703],\n",
       "       [0.5006712 ],\n",
       "       [0.5011523 ],\n",
       "       [0.500278  ],\n",
       "       [0.4971108 ],\n",
       "       [0.5013008 ],\n",
       "       [0.49746433],\n",
       "       [0.49687746],\n",
       "       [0.49978432],\n",
       "       [0.5006823 ],\n",
       "       [0.5001516 ],\n",
       "       [0.4981635 ],\n",
       "       [0.49921435],\n",
       "       [0.4979458 ],\n",
       "       [0.50130343],\n",
       "       [0.49949145],\n",
       "       [0.4983746 ],\n",
       "       [0.499701  ],\n",
       "       [0.4992972 ],\n",
       "       [0.5013076 ],\n",
       "       [0.49926546],\n",
       "       [0.4989213 ],\n",
       "       [0.5011236 ],\n",
       "       [0.5001869 ],\n",
       "       [0.5007742 ],\n",
       "       [0.4978202 ],\n",
       "       [0.49895707],\n",
       "       [0.5008163 ],\n",
       "       [0.5004207 ],\n",
       "       [0.5013068 ],\n",
       "       [0.5000863 ],\n",
       "       [0.4975307 ],\n",
       "       [0.500288  ],\n",
       "       [0.49857926],\n",
       "       [0.500654  ],\n",
       "       [0.49865282],\n",
       "       [0.5013076 ],\n",
       "       [0.50130224],\n",
       "       [0.4998538 ],\n",
       "       [0.49906325],\n",
       "       [0.5004439 ],\n",
       "       [0.5010818 ],\n",
       "       [0.5005423 ],\n",
       "       [0.50101215],\n",
       "       [0.49941763],\n",
       "       [0.49945542],\n",
       "       [0.5013076 ],\n",
       "       [0.49997804],\n",
       "       [0.50006384],\n",
       "       [0.5000518 ],\n",
       "       [0.5012862 ],\n",
       "       [0.4979987 ],\n",
       "       [0.5011803 ],\n",
       "       [0.4988132 ],\n",
       "       [0.5008437 ],\n",
       "       [0.49953443],\n",
       "       [0.5008568 ],\n",
       "       [0.5002898 ],\n",
       "       [0.49870133],\n",
       "       [0.50045276],\n",
       "       [0.49757653],\n",
       "       [0.50113094],\n",
       "       [0.4989158 ],\n",
       "       [0.5005986 ],\n",
       "       [0.4995985 ],\n",
       "       [0.5013076 ],\n",
       "       [0.49880993],\n",
       "       [0.5001851 ],\n",
       "       [0.50101036],\n",
       "       [0.5006578 ],\n",
       "       [0.5000419 ],\n",
       "       [0.49892232],\n",
       "       [0.5012935 ],\n",
       "       [0.49930304],\n",
       "       [0.5004123 ],\n",
       "       [0.5012912 ],\n",
       "       [0.4996105 ],\n",
       "       [0.5002092 ],\n",
       "       [0.5013053 ],\n",
       "       [0.5007118 ],\n",
       "       [0.49983507],\n",
       "       [0.4998678 ],\n",
       "       [0.5012877 ],\n",
       "       [0.5011351 ],\n",
       "       [0.50126886],\n",
       "       [0.5013076 ],\n",
       "       [0.5013076 ],\n",
       "       [0.50038016],\n",
       "       [0.49927425],\n",
       "       [0.49879575],\n",
       "       [0.5001082 ],\n",
       "       [0.5012196 ],\n",
       "       [0.49962386],\n",
       "       [0.49910942],\n",
       "       [0.4995446 ],\n",
       "       [0.50069577],\n",
       "       [0.49926284],\n",
       "       [0.50085866],\n",
       "       [0.499026  ],\n",
       "       [0.5010112 ],\n",
       "       [0.501167  ],\n",
       "       [0.49916235],\n",
       "       [0.4997519 ],\n",
       "       [0.50031877],\n",
       "       [0.5004397 ],\n",
       "       [0.498783  ],\n",
       "       [0.5005203 ],\n",
       "       [0.49956694],\n",
       "       [0.49994674],\n",
       "       [0.50009626],\n",
       "       [0.49928007],\n",
       "       [0.50034744],\n",
       "       [0.49818376],\n",
       "       [0.50102836],\n",
       "       [0.49923837],\n",
       "       [0.5008199 ],\n",
       "       [0.49965447],\n",
       "       [0.49934524],\n",
       "       [0.5012246 ],\n",
       "       [0.50039613],\n",
       "       [0.49912792],\n",
       "       [0.50058657],\n",
       "       [0.49839315],\n",
       "       [0.49966028],\n",
       "       [0.49865893],\n",
       "       [0.49973702],\n",
       "       [0.4991335 ],\n",
       "       [0.50053847],\n",
       "       [0.5006954 ],\n",
       "       [0.5009698 ],\n",
       "       [0.5003123 ],\n",
       "       [0.49834424],\n",
       "       [0.5005841 ],\n",
       "       [0.5001183 ],\n",
       "       [0.5012721 ],\n",
       "       [0.4987894 ],\n",
       "       [0.5003754 ],\n",
       "       [0.49954036],\n",
       "       [0.4993217 ],\n",
       "       [0.50129133],\n",
       "       [0.4979908 ],\n",
       "       [0.5009375 ],\n",
       "       [0.49910077],\n",
       "       [0.5000482 ],\n",
       "       [0.49933293],\n",
       "       [0.5004123 ],\n",
       "       [0.5012391 ],\n",
       "       [0.4994006 ],\n",
       "       [0.49989337],\n",
       "       [0.5000194 ],\n",
       "       [0.4999542 ],\n",
       "       [0.501305  ],\n",
       "       [0.5002952 ],\n",
       "       [0.49971703],\n",
       "       [0.49909687],\n",
       "       [0.49999282],\n",
       "       [0.49980277],\n",
       "       [0.49794102],\n",
       "       [0.4986725 ],\n",
       "       [0.49953723],\n",
       "       [0.49943537],\n",
       "       [0.49973324],\n",
       "       [0.49693316],\n",
       "       [0.5009747 ],\n",
       "       [0.50039077],\n",
       "       [0.4993388 ],\n",
       "       [0.501307  ],\n",
       "       [0.50100076],\n",
       "       [0.5013069 ],\n",
       "       [0.49867234],\n",
       "       [0.5006898 ],\n",
       "       [0.49942973],\n",
       "       [0.5012971 ],\n",
       "       [0.5003916 ],\n",
       "       [0.5013076 ],\n",
       "       [0.5012848 ],\n",
       "       [0.4998435 ],\n",
       "       [0.49974135],\n",
       "       [0.49857602],\n",
       "       [0.4990722 ],\n",
       "       [0.50000566],\n",
       "       [0.49844462],\n",
       "       [0.49999145],\n",
       "       [0.5004575 ],\n",
       "       [0.49995628],\n",
       "       [0.50010604],\n",
       "       [0.49816903],\n",
       "       [0.50075257],\n",
       "       [0.49946296],\n",
       "       [0.5013076 ],\n",
       "       [0.50094116],\n",
       "       [0.50006527],\n",
       "       [0.50053746],\n",
       "       [0.5006335 ],\n",
       "       [0.5007179 ],\n",
       "       [0.4995641 ],\n",
       "       [0.50058115],\n",
       "       [0.5011237 ],\n",
       "       [0.49864954],\n",
       "       [0.4995516 ],\n",
       "       [0.4990964 ],\n",
       "       [0.49820286],\n",
       "       [0.5013076 ],\n",
       "       [0.5013076 ],\n",
       "       [0.5007031 ],\n",
       "       [0.5011644 ],\n",
       "       [0.5013076 ],\n",
       "       [0.5013076 ],\n",
       "       [0.49959233],\n",
       "       [0.5002492 ],\n",
       "       [0.49939132],\n",
       "       [0.501     ],\n",
       "       [0.49919024],\n",
       "       [0.49979618],\n",
       "       [0.49995142],\n",
       "       [0.49990806],\n",
       "       [0.49995166],\n",
       "       [0.5008797 ],\n",
       "       [0.50047296],\n",
       "       [0.49926516],\n",
       "       [0.4998737 ],\n",
       "       [0.4993708 ],\n",
       "       [0.49982563],\n",
       "       [0.49912283],\n",
       "       [0.49955785],\n",
       "       [0.5012125 ],\n",
       "       [0.50027406],\n",
       "       [0.49824837],\n",
       "       [0.49983266],\n",
       "       [0.49910083],\n",
       "       [0.50000787],\n",
       "       [0.50062025],\n",
       "       [0.500067  ],\n",
       "       [0.4994932 ],\n",
       "       [0.5005683 ],\n",
       "       [0.49771354],\n",
       "       [0.50113595],\n",
       "       [0.49945062],\n",
       "       [0.49954453],\n",
       "       [0.50111747],\n",
       "       [0.50124115],\n",
       "       [0.49991435],\n",
       "       [0.49965534],\n",
       "       [0.49845535],\n",
       "       [0.5009764 ],\n",
       "       [0.5000357 ],\n",
       "       [0.49908826],\n",
       "       [0.49895942],\n",
       "       [0.49995726],\n",
       "       [0.50025535],\n",
       "       [0.49968603],\n",
       "       [0.50025517],\n",
       "       [0.5006363 ],\n",
       "       [0.5013076 ],\n",
       "       [0.49922028],\n",
       "       [0.49954602],\n",
       "       [0.50007206],\n",
       "       [0.5013076 ],\n",
       "       [0.5013076 ],\n",
       "       [0.50115895],\n",
       "       [0.5013076 ],\n",
       "       [0.49822497],\n",
       "       [0.49866116],\n",
       "       [0.50097346],\n",
       "       [0.50025946],\n",
       "       [0.5012909 ],\n",
       "       [0.49999657],\n",
       "       [0.501171  ],\n",
       "       [0.4999546 ],\n",
       "       [0.50028014],\n",
       "       [0.5009685 ],\n",
       "       [0.4994353 ],\n",
       "       [0.4996229 ],\n",
       "       [0.50060624],\n",
       "       [0.4985036 ],\n",
       "       [0.5013012 ],\n",
       "       [0.49934912],\n",
       "       [0.49965933],\n",
       "       [0.4979851 ],\n",
       "       [0.50006264],\n",
       "       [0.4992241 ],\n",
       "       [0.4999431 ],\n",
       "       [0.50007236],\n",
       "       [0.5000235 ],\n",
       "       [0.4946513 ],\n",
       "       [0.49744877],\n",
       "       [0.5008566 ],\n",
       "       [0.5007413 ],\n",
       "       [0.5013076 ],\n",
       "       [0.49946982],\n",
       "       [0.5012584 ],\n",
       "       [0.4987969 ],\n",
       "       [0.49983218],\n",
       "       [0.49951988],\n",
       "       [0.49948362],\n",
       "       [0.5010212 ],\n",
       "       [0.4998413 ],\n",
       "       [0.4992009 ],\n",
       "       [0.49943164],\n",
       "       [0.49807966],\n",
       "       [0.49964008],\n",
       "       [0.501111  ],\n",
       "       [0.5013076 ],\n",
       "       [0.5010052 ],\n",
       "       [0.49884906],\n",
       "       [0.50083786],\n",
       "       [0.5008406 ],\n",
       "       [0.49975246],\n",
       "       [0.5008513 ],\n",
       "       [0.49724132],\n",
       "       [0.50121033],\n",
       "       [0.5013076 ],\n",
       "       [0.5013076 ],\n",
       "       [0.49957237],\n",
       "       [0.4997075 ],\n",
       "       [0.5001818 ],\n",
       "       [0.5012723 ],\n",
       "       [0.5009022 ],\n",
       "       [0.4998857 ],\n",
       "       [0.5004868 ],\n",
       "       [0.49982676],\n",
       "       [0.5004991 ],\n",
       "       [0.50049216],\n",
       "       [0.50007004],\n",
       "       [0.5007024 ],\n",
       "       [0.4996058 ],\n",
       "       [0.5010935 ],\n",
       "       [0.49851936],\n",
       "       [0.49925518],\n",
       "       [0.49881384],\n",
       "       [0.4990625 ],\n",
       "       [0.4995603 ],\n",
       "       [0.5000692 ],\n",
       "       [0.49982578],\n",
       "       [0.49801096],\n",
       "       [0.5013076 ],\n",
       "       [0.5012956 ],\n",
       "       [0.49839798],\n",
       "       [0.5001657 ],\n",
       "       [0.5001403 ],\n",
       "       [0.50058234],\n",
       "       [0.50022405],\n",
       "       [0.49876106],\n",
       "       [0.50064117],\n",
       "       [0.5013018 ],\n",
       "       [0.49993923],\n",
       "       [0.50083554],\n",
       "       [0.5000969 ],\n",
       "       [0.5012833 ],\n",
       "       [0.50053954],\n",
       "       [0.50050795],\n",
       "       [0.50100034],\n",
       "       [0.50075847],\n",
       "       [0.49984184],\n",
       "       [0.49948794],\n",
       "       [0.49985465],\n",
       "       [0.4998057 ],\n",
       "       [0.5008658 ],\n",
       "       [0.50042665],\n",
       "       [0.49921948],\n",
       "       [0.49908194],\n",
       "       [0.5001857 ],\n",
       "       [0.49926192],\n",
       "       [0.5013076 ],\n",
       "       [0.49878603],\n",
       "       [0.49922696],\n",
       "       [0.5011632 ],\n",
       "       [0.50049144],\n",
       "       [0.50076395],\n",
       "       [0.49696413],\n",
       "       [0.49855104],\n",
       "       [0.500376  ],\n",
       "       [0.5011135 ],\n",
       "       [0.49920413],\n",
       "       [0.4990097 ],\n",
       "       [0.49923968],\n",
       "       [0.5003479 ],\n",
       "       [0.50064236],\n",
       "       [0.50083125],\n",
       "       [0.50125146],\n",
       "       [0.50110376],\n",
       "       [0.5005319 ],\n",
       "       [0.4999981 ],\n",
       "       [0.50124633],\n",
       "       [0.5011657 ],\n",
       "       [0.5001366 ],\n",
       "       [0.50051886],\n",
       "       [0.4994379 ],\n",
       "       [0.5001421 ],\n",
       "       [0.5008808 ],\n",
       "       [0.5013076 ],\n",
       "       [0.50070435],\n",
       "       [0.49965128],\n",
       "       [0.5012176 ],\n",
       "       [0.50033516],\n",
       "       [0.49847785],\n",
       "       [0.4992828 ],\n",
       "       [0.49967116],\n",
       "       [0.4996089 ],\n",
       "       [0.50014687],\n",
       "       [0.5003025 ],\n",
       "       [0.49975836],\n",
       "       [0.49876848],\n",
       "       [0.49860695],\n",
       "       [0.49865678],\n",
       "       [0.49827403],\n",
       "       [0.50079393],\n",
       "       [0.49892703],\n",
       "       [0.5010884 ],\n",
       "       [0.50107765],\n",
       "       [0.49869746],\n",
       "       [0.50120884],\n",
       "       [0.5001664 ],\n",
       "       [0.4993026 ],\n",
       "       [0.49947563],\n",
       "       [0.5005071 ],\n",
       "       [0.5013076 ],\n",
       "       [0.49776646],\n",
       "       [0.5006783 ],\n",
       "       [0.500668  ],\n",
       "       [0.49796447],\n",
       "       [0.5012385 ],\n",
       "       [0.49944982],\n",
       "       [0.4990921 ],\n",
       "       [0.5013068 ],\n",
       "       [0.49903023],\n",
       "       [0.49995226],\n",
       "       [0.50033075],\n",
       "       [0.5003908 ],\n",
       "       [0.5002478 ],\n",
       "       [0.5008218 ],\n",
       "       [0.5007829 ],\n",
       "       [0.5005157 ],\n",
       "       [0.50124747],\n",
       "       [0.5010297 ],\n",
       "       [0.50061107],\n",
       "       [0.50092554],\n",
       "       [0.49990404],\n",
       "       [0.5008139 ],\n",
       "       [0.49955404],\n",
       "       [0.4986779 ],\n",
       "       [0.500562  ],\n",
       "       [0.50034815],\n",
       "       [0.501009  ],\n",
       "       [0.49860385],\n",
       "       [0.50046563],\n",
       "       [0.49970523],\n",
       "       [0.5000662 ],\n",
       "       [0.49794894],\n",
       "       [0.50075555],\n",
       "       [0.4991598 ],\n",
       "       [0.49772006],\n",
       "       [0.5004931 ],\n",
       "       [0.4980349 ],\n",
       "       [0.5001638 ],\n",
       "       [0.49986798],\n",
       "       [0.49911392],\n",
       "       [0.50122386],\n",
       "       [0.49994567],\n",
       "       [0.4972744 ],\n",
       "       [0.5003246 ],\n",
       "       [0.4993511 ],\n",
       "       [0.500354  ],\n",
       "       [0.49908963],\n",
       "       [0.49834573],\n",
       "       [0.49654916],\n",
       "       [0.4983198 ],\n",
       "       [0.5008956 ],\n",
       "       [0.49921617],\n",
       "       [0.49853227],\n",
       "       [0.49940264],\n",
       "       [0.49757257],\n",
       "       [0.50092655],\n",
       "       [0.4997718 ],\n",
       "       [0.49947807],\n",
       "       [0.4984364 ],\n",
       "       [0.50065106],\n",
       "       [0.50053304],\n",
       "       [0.4980939 ],\n",
       "       [0.5011497 ],\n",
       "       [0.49786362],\n",
       "       [0.5013076 ],\n",
       "       [0.4999872 ],\n",
       "       [0.50046027],\n",
       "       [0.49914867],\n",
       "       [0.49610716],\n",
       "       [0.5012879 ],\n",
       "       [0.5003966 ],\n",
       "       [0.5002349 ],\n",
       "       [0.5006874 ],\n",
       "       [0.49873483],\n",
       "       [0.5005346 ],\n",
       "       [0.50119066],\n",
       "       [0.50034356],\n",
       "       [0.5012941 ],\n",
       "       [0.4993862 ],\n",
       "       [0.49939418],\n",
       "       [0.501171  ],\n",
       "       [0.4999511 ],\n",
       "       [0.50111383],\n",
       "       [0.498274  ],\n",
       "       [0.5012421 ],\n",
       "       [0.49884814],\n",
       "       [0.50055325],\n",
       "       [0.49739817],\n",
       "       [0.5002411 ],\n",
       "       [0.50039345],\n",
       "       [0.5004305 ],\n",
       "       [0.4988393 ],\n",
       "       [0.50020534],\n",
       "       [0.49950513],\n",
       "       [0.49939767],\n",
       "       [0.5010089 ]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e9379144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = preds.mean()\n",
    "binary_predictions = [1 if prediction > threshold else 0 for prediction in train_preds]\n",
    "binary_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c8363a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4321\n",
      "Recall: 0.5440\n",
      "F1-Score: 0.4816\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(train_generator.classes, binary_predictions)\n",
    "recall = recall_score(train_generator.classes, binary_predictions)\n",
    "f1 = f1_score(train_generator.classes, binary_predictions)\n",
    "\n",
    "# Print the metrics\n",
    "#print(\"Loss: {:.4f}\".format(test_loss_airbags))\n",
    "#print(\"Accuracy: {:.4f}\".format(test_acc_airbags))\n",
    "print(\"Precision: {:.4f}\".format(precision))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "print(\"F1-Score: {:.4f}\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eed1f66",
   "metadata": {},
   "source": [
    "# CHanging to probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22bef43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e43b04a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dimension = (224, 224, 3)\n",
    "\n",
    "metrics1 = [TruePositives(), FalsePositives(), TrueNegatives(), FalseNegatives()]\n",
    "\n",
    "soft_model = Sequential([\n",
    "    layers.Resizing(224, 224),\n",
    "    layers.Rescaling(1./255),\n",
    "    #layers.RandomFlip(mode=\"horizontal_and_vertical\"),\n",
    "    #layers.RandomTranslation(height_factor=0.2, width_factor=0.2),\n",
    "    #layers.RandomRotation(0.2),\n",
    "    #layers.RandomContrast(factor=0.2),\n",
    "    #layers.RandomBrightness(factor=0.2),\n",
    "    \n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_dimension),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    #layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    #layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    #layers.Dropout(0.5),\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dense(128, activation='relu'),\n",
    "    #layers.Dropout(0.5),\n",
    "    \n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "soft_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=metrics1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0150f0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "106/106 [==============================] - 331s 3s/step - loss: 1.5747 - true_positives_5: 395.0000 - false_positives_5: 465.0000 - true_negatives_5: 1451.0000 - false_negatives_5: 1061.0000 - val_loss: 0.6887 - val_true_positives_5: 9.0000 - val_false_positives_5: 7.0000 - val_true_negatives_5: 331.0000 - val_false_negatives_5: 247.0000\n",
      "Epoch 2/5\n",
      "106/106 [==============================] - 327s 3s/step - loss: 0.6755 - true_positives_5: 410.0000 - false_positives_5: 359.0000 - true_negatives_5: 1557.0000 - false_negatives_5: 1046.0000 - val_loss: 0.6905 - val_true_positives_5: 136.0000 - val_false_positives_5: 137.0000 - val_true_negatives_5: 201.0000 - val_false_negatives_5: 120.0000\n",
      "Epoch 3/5\n",
      "106/106 [==============================] - 355s 3s/step - loss: 0.6639 - true_positives_5: 519.0000 - false_positives_5: 424.0000 - true_negatives_5: 1492.0000 - false_negatives_5: 937.0000 - val_loss: 0.6736 - val_true_positives_5: 75.0000 - val_false_positives_5: 58.0000 - val_true_negatives_5: 280.0000 - val_false_negatives_5: 181.0000\n",
      "Epoch 4/5\n",
      "106/106 [==============================] - 322s 3s/step - loss: 0.6630 - true_positives_5: 605.0000 - false_positives_5: 461.0000 - true_negatives_5: 1455.0000 - false_negatives_5: 851.0000 - val_loss: 0.6680 - val_true_positives_5: 65.0000 - val_false_positives_5: 42.0000 - val_true_negatives_5: 296.0000 - val_false_negatives_5: 191.0000\n",
      "Epoch 5/5\n",
      "106/106 [==============================] - 319s 3s/step - loss: 0.6419 - true_positives_5: 564.0000 - false_positives_5: 340.0000 - true_negatives_5: 1576.0000 - false_negatives_5: 892.0000 - val_loss: 0.6705 - val_true_positives_5: 118.0000 - val_false_positives_5: 99.0000 - val_true_negatives_5: 239.0000 - val_false_negatives_5: 138.0000\n"
     ]
    }
   ],
   "source": [
    "soft_hist = soft_model.fit(train_generator, epochs=5, batch_size=32, validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "08183c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47796610169491527"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = 564/(564+(.5*(340+892)))\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ee564c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 69s 2s/step\n",
      "106/106 [==============================] - 234s 2s/step\n",
      "19/19 [==============================] - 41s 2s/step\n"
     ]
    }
   ],
   "source": [
    "soft_preds = soft_model.predict(test_generator)\n",
    "soft_train_preds = soft_model.predict(train_generator)\n",
    "soft_val_preds = soft_model.predict(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af14bd72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46337956"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_train_preds.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5018e587",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = soft_train_preds.mean()\n",
    "binary_predictions_soft = [1 if prediction > threshold else 0 for prediction in soft_train_preds]\n",
    "binary_predictions_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dca816ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4324\n",
      "Recall: 0.4918\n",
      "F1-Score: 0.4602\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(train_generator.classes, binary_predictions_soft)\n",
    "recall = recall_score(train_generator.classes, binary_predictions_soft)\n",
    "f1 = f1_score(train_generator.classes, binary_predictions_soft)\n",
    "\n",
    "# Print the metrics\n",
    "#print(\"Loss: {:.4f}\".format(test_loss_airbags))\n",
    "#print(\"Accuracy: {:.4f}\".format(test_acc_airbags))\n",
    "print(\"Precision: {:.4f}\".format(precision))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "print(\"F1-Score: {:.4f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598acc4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58676699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e5a0c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
